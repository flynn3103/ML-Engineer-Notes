{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXb2gfxlhoUB"
      },
      "source": [
        "# Cost Sensitive Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ietyDzvUhoUH",
        "outputId": "35703046-d36c-4992-fcec-6a4d9beb463c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/flynn/anaconda3\n",
            "\n",
            "  added / updated specs:\n",
            "    - xgboost\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _py-xgboost-mutex-2.0      |            cpu_0           9 KB\n",
            "    conda-4.11.0               |   py39h06a4308_0        14.4 MB\n",
            "    libxgboost-1.5.0           |       h295c915_1         2.0 MB\n",
            "    py-xgboost-1.5.0           |   py39h06a4308_1         163 KB\n",
            "    xgboost-1.5.0              |   py39h06a4308_1          25 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        16.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _py-xgboost-mutex  pkgs/main/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
            "  libxgboost         pkgs/main/linux-64::libxgboost-1.5.0-h295c915_1\n",
            "  py-xgboost         pkgs/main/linux-64::py-xgboost-1.5.0-py39h06a4308_1\n",
            "  xgboost            pkgs/main/linux-64::xgboost-1.5.0-py39h06a4308_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                               4.10.3-py39h06a4308_0 --> 4.11.0-py39h06a4308_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "conda-4.11.0         | 14.4 MB   | ##################################### | 100% \n",
            "py-xgboost-1.5.0     | 163 KB    | ##################################### | 100% \n",
            "xgboost-1.5.0        | 25 KB     | ##################################### | 100% \n",
            "libxgboost-1.5.0     | 2.0 MB    | ##################################### | 100% \n",
            "_py-xgboost-mutex-2. | 9 KB      | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%conda install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ww6k_qYhoUK"
      },
      "source": [
        "## Grid Search Weighted for ML Classification\n",
        "\n",
        "Using a class weighting that is the inverse ratio of the training data is just a heuristic. \n",
        "\n",
        "It is\n",
        "possible that better performance can be achieved with a different class weighting, and this too\n",
        "will depend on the choice of performance metric used to evaluate the model. \n",
        "\n",
        "In this section, we\n",
        "will grid search a range of different class weightings for weighted logistic regression and discover\n",
        "which results in the best ROC AUC score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-djjCyXhoUL",
        "outputId": "a1c6b5e9-0e20-4ed0-b971-669d00cc31fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best: 0.988943 using {'class_weight': {0: 1, 1: 100}} \n",
            " 0.982148 (0.017020) with: {'class_weight': {0: 100, 1: 1}} \n",
            " 0.983465 (0.015555) with: {'class_weight': {0: 10, 1: 1}} \n",
            " 0.985242 (0.013456) with: {'class_weight': {0: 1, 1: 1}} \n",
            " 0.987973 (0.009846) with: {'class_weight': {0: 1, 1: 10}} \n",
            " 0.988943 (0.006354) with: {'class_weight': {0: 1, 1: 100}} \n"
          ]
        }
      ],
      "source": [
        "# grid search class weights with logistic regression for imbalanced classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# generate dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
        "# define model\n",
        "model = LogisticRegression(solver= 'lbfgs' )\n",
        "# model = SVC(gamma= ' scale ' )\n",
        "# define grid\n",
        "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
        "param_grid = dict(class_weight=balance)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\n",
        "scoring= 'roc_auc' )\n",
        "# execute the grid search\n",
        "grid_result = grid.fit(X, y)\n",
        "# report the best configuration\n",
        "print( ' Best: %f using %s ' % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_[ 'mean_test_score' ]\n",
        "stds = grid_result.cv_results_[ 'std_test_score' ]\n",
        "params = grid_result.cv_results_[ 'params' ]\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print( ' %f (%f) with: %r ' % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCMIIj3fhoUM"
      },
      "source": [
        "## Cost-Sensitive Gradient Boosting with XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k4EckeJhoUN",
        "outputId": "1caaf1fe-51ae-42a6-8f79-d61d04da50d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.960155 using {'scale_pos_weight': 1000}\n",
            "0.953721 (0.035950) with: {'scale_pos_weight': 1}\n",
            "0.958254 (0.028362) with: {'scale_pos_weight': 10}\n",
            "0.957892 (0.027283) with: {'scale_pos_weight': 25}\n",
            "0.959157 (0.027430) with: {'scale_pos_weight': 50}\n",
            "0.959241 (0.028015) with: {'scale_pos_weight': 75}\n",
            "0.959305 (0.028286) with: {'scale_pos_weight': 99}\n",
            "0.959505 (0.028213) with: {'scale_pos_weight': 100}\n",
            "0.960155 (0.028721) with: {'scale_pos_weight': 1000}\n"
          ]
        }
      ],
      "source": [
        "# grid search positive class weights with xgboost for imbalance classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "# generate dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=7)\n",
        "# define model\n",
        "model = XGBClassifier()\n",
        "# define grid\n",
        "weights = [1, 10, 25, 50, 75, 99, 100, 1000]\n",
        "param_grid = dict(scale_pos_weight=weights)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\n",
        "scoring= 'roc_auc' )\n",
        "# execute the grid search\n",
        "grid_result = grid.fit(X, y)\n",
        "# report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_[ 'mean_test_score' ]\n",
        "stds = grid_result.cv_results_[ 'std_test_score' ]\n",
        "params = grid_result.cv_results_[ 'params' ]\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 2.7.18 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "3_cost_sensitive.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}